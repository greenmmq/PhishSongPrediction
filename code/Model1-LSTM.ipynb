{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6acc82a0-8805-4655-9fab-e50295c08d06",
      "metadata": {
        "id": "6acc82a0-8805-4655-9fab-e50295c08d06"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "This first section queries the phish.net API to get a long csv of phish setlist data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "13cf59c1",
      "metadata": {
        "id": "13cf59c1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Masking\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8fed00ed",
      "metadata": {
        "id": "8fed00ed"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/allphishsets.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0bbc5b2-f8d2-408c-9d96-dceb9969b963",
      "metadata": {
        "id": "e0bbc5b2-f8d2-408c-9d96-dceb9969b963"
      },
      "source": [
        "This section explores the downloaded data and transforms the infrequently played songs into the \"wildcard\" song."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d46bfb70-6d2d-4487-a102-bb9f6095aeea",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "d46bfb70-6d2d-4487-a102-bb9f6095aeea",
        "outputId": "1b494108-c978-4c21-b183-103ef9be8846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        showdate                                               full\n",
              "0     1985-05-03  set-1|slave-to-the-traffic-light|mikes-song|da...\n",
              "1     1986-04-01  set-1|quinn-the-eskimo-the-mighty-quinn|have-m...\n",
              "2     1986-10-15  set-1|alumni-blues|makisupa-policeman|skin-it-...\n",
              "3     1987-03-06  set-1|funky-bitch|good-times-bad-times|corinna...\n",
              "4     1987-04-29  set-1|she-caught-the-katy-and-left-me-a-mule-t...\n",
              "...          ...                                                ...\n",
              "1545  2023-10-10  set-1|sigma-oasis|the-9th-cube|theme-from-the-...\n",
              "1546  2023-10-11  set-1|set-your-soul-free|funky-bitch|roggae|ki...\n",
              "1547  2023-10-13  set-1|carini|rift|halleys-comet|ghost|albuquer...\n",
              "1548  2023-10-14  set-1|runaway-jim|martian-monster|sample-in-a-...\n",
              "1549  2023-10-15  set-1|everything-is-hollow|timber-jerry-the-mu...\n",
              "\n",
              "[1550 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6a47c51-a1b1-412f-9bf0-e2f25cbc4674\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>showdate</th>\n",
              "      <th>full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1985-05-03</td>\n",
              "      <td>set-1|slave-to-the-traffic-light|mikes-song|da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1986-04-01</td>\n",
              "      <td>set-1|quinn-the-eskimo-the-mighty-quinn|have-m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1986-10-15</td>\n",
              "      <td>set-1|alumni-blues|makisupa-policeman|skin-it-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1987-03-06</td>\n",
              "      <td>set-1|funky-bitch|good-times-bad-times|corinna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1987-04-29</td>\n",
              "      <td>set-1|she-caught-the-katy-and-left-me-a-mule-t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1545</th>\n",
              "      <td>2023-10-10</td>\n",
              "      <td>set-1|sigma-oasis|the-9th-cube|theme-from-the-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>2023-10-11</td>\n",
              "      <td>set-1|set-your-soul-free|funky-bitch|roggae|ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>2023-10-13</td>\n",
              "      <td>set-1|carini|rift|halleys-comet|ghost|albuquer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1548</th>\n",
              "      <td>2023-10-14</td>\n",
              "      <td>set-1|runaway-jim|martian-monster|sample-in-a-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>2023-10-15</td>\n",
              "      <td>set-1|everything-is-hollow|timber-jerry-the-mu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1550 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a47c51-a1b1-412f-9bf0-e2f25cbc4674')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6a47c51-a1b1-412f-9bf0-e2f25cbc4674 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6a47c51-a1b1-412f-9bf0-e2f25cbc4674');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0680d26-089a-45d7-9e2e-48a141111bf2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0680d26-089a-45d7-9e2e-48a141111bf2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0680d26-089a-45d7-9e2e-48a141111bf2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "songstring = df[['showdate','set','slug']].groupby(['showdate','set'])['slug']\\\n",
        "                                          .apply(lambda x: '|'.join(x)).reset_index()\n",
        "songstring['full'] = songstring.apply(lambda row: f\"set-{row['set']}|{row['slug']}\", axis=1)\n",
        "\n",
        "songstring = songstring[['showdate','full']].groupby(['showdate'])['full']\\\n",
        "                                            .apply(lambda x: '|'.join(x)).reset_index()\n",
        "\n",
        "songstring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a71dab9",
      "metadata": {
        "id": "6a71dab9"
      },
      "outputs": [],
      "source": [
        "# Pre-processing: tokenizing songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d87cfd7c",
      "metadata": {
        "id": "d87cfd7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "songs = songstring['full'].str.split('|').apply(lambda x: [song.replace('-', ' ') for song in x])\n",
        "unique_songs = list(set(song for sublist in songs for song in sublist))\n",
        "num_songs = len(unique_songs)\n",
        "\n",
        "# Encode songs into numerical values\n",
        "song_to_index = {song: i for i, song in enumerate(unique_songs)}\n",
        "index_to_song = {i: song for i, song in enumerate(unique_songs)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475c8ac5",
      "metadata": {
        "id": "475c8ac5"
      },
      "outputs": [],
      "source": [
        "# 0 list in X, 1th list in y, 2nd list in X, 3rd list in y and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e0521b48",
      "metadata": {
        "id": "e0521b48"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create input sequences and target sequences\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "for i in range(len(songs) - 1):\n",
        "    input_seq = songs.iloc[i]\n",
        "    target_seq = songs.iloc[i + 1]\n",
        "    input_sequences.append([song_to_index[song] for song in input_seq])\n",
        "    target_sequences.append([song_to_index[song] for song in target_seq])\n",
        "\n",
        "# Pad sequences to make them of the same length\n",
        "X = pad_sequences(input_sequences, padding='pre', truncating='pre')\n",
        "y = pad_sequences(target_sequences, padding='pre', truncating='pre')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "062c5601",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "062c5601",
        "outputId": "90bb34a3-7cf7-4f60-a119-43b794473045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 36s 258ms/step - loss: 5.0677 - accuracy: 0.5075 - val_loss: 3.4177 - val_accuracy: 0.5519\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 2s 64ms/step - loss: 3.3413 - accuracy: 0.5521 - val_loss: 3.2411 - val_accuracy: 0.5519\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 2s 62ms/step - loss: 3.2418 - accuracy: 0.5521 - val_loss: 3.1911 - val_accuracy: 0.5519\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 2s 64ms/step - loss: 3.1876 - accuracy: 0.5521 - val_loss: 3.1117 - val_accuracy: 0.5519\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 3.0952 - accuracy: 0.5521 - val_loss: 3.0294 - val_accuracy: 0.5519\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 2.9941 - accuracy: 0.5521 - val_loss: 2.9096 - val_accuracy: 0.5519\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 2.8698 - accuracy: 0.5521 - val_loss: 2.7790 - val_accuracy: 0.5519\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 2.7338 - accuracy: 0.5521 - val_loss: 2.6486 - val_accuracy: 0.5519\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 1s 39ms/step - loss: 2.6310 - accuracy: 0.5521 - val_loss: 2.5986 - val_accuracy: 0.5519\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 2.5736 - accuracy: 0.5530 - val_loss: 2.5531 - val_accuracy: 0.5519\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 2.5513 - accuracy: 0.5602 - val_loss: 2.5612 - val_accuracy: 0.5551\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.5400 - accuracy: 0.5648 - val_loss: 2.5302 - val_accuracy: 0.5783\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 2.5171 - accuracy: 0.5670 - val_loss: 2.5160 - val_accuracy: 0.5811\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.5008 - accuracy: 0.5737 - val_loss: 2.5066 - val_accuracy: 0.5806\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.4851 - accuracy: 0.5780 - val_loss: 2.4789 - val_accuracy: 0.5793\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.4649 - accuracy: 0.5804 - val_loss: 2.4675 - val_accuracy: 0.5803\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 2.4558 - accuracy: 0.5826 - val_loss: 2.4657 - val_accuracy: 0.5819\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.4438 - accuracy: 0.5833 - val_loss: 2.4486 - val_accuracy: 0.5834\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.4314 - accuracy: 0.5844 - val_loss: 2.4543 - val_accuracy: 0.5832\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 2.4249 - accuracy: 0.5843 - val_loss: 2.4430 - val_accuracy: 0.5821\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.4095 - accuracy: 0.5857 - val_loss: 2.4162 - val_accuracy: 0.5856\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.3994 - accuracy: 0.5861 - val_loss: 2.4081 - val_accuracy: 0.5859\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.3973 - accuracy: 0.5862 - val_loss: 2.4169 - val_accuracy: 0.5849\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.3955 - accuracy: 0.5859 - val_loss: 2.4078 - val_accuracy: 0.5848\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 2.3811 - accuracy: 0.5868 - val_loss: 2.3989 - val_accuracy: 0.5856\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 2.3743 - accuracy: 0.5868 - val_loss: 2.4221 - val_accuracy: 0.5823\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 2.3747 - accuracy: 0.5871 - val_loss: 2.3899 - val_accuracy: 0.5862\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 2.3646 - accuracy: 0.5874 - val_loss: 2.3874 - val_accuracy: 0.5864\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 2.3576 - accuracy: 0.5879 - val_loss: 2.3819 - val_accuracy: 0.5867\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 2.3466 - accuracy: 0.5882 - val_loss: 2.3745 - val_accuracy: 0.5871\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 2.3504 - accuracy: 0.5870 - val_loss: 2.3705 - val_accuracy: 0.5861\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 2.3353 - accuracy: 0.5883 - val_loss: 2.3694 - val_accuracy: 0.5870\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.3264 - accuracy: 0.5886 - val_loss: 2.3518 - val_accuracy: 0.5876\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.3207 - accuracy: 0.5884 - val_loss: 2.3480 - val_accuracy: 0.5875\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.3065 - accuracy: 0.5885 - val_loss: 2.3384 - val_accuracy: 0.5877\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2982 - accuracy: 0.5895 - val_loss: 2.3363 - val_accuracy: 0.5879\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 2.2932 - accuracy: 0.5897 - val_loss: 2.3384 - val_accuracy: 0.5869\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.2860 - accuracy: 0.5895 - val_loss: 2.3214 - val_accuracy: 0.5872\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2790 - accuracy: 0.5903 - val_loss: 2.3246 - val_accuracy: 0.5889\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.2749 - accuracy: 0.5902 - val_loss: 2.3403 - val_accuracy: 0.5867\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2699 - accuracy: 0.5901 - val_loss: 2.3121 - val_accuracy: 0.5883\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2637 - accuracy: 0.5908 - val_loss: 2.3089 - val_accuracy: 0.5880\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2585 - accuracy: 0.5906 - val_loss: 2.3052 - val_accuracy: 0.5877\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2536 - accuracy: 0.5910 - val_loss: 2.3072 - val_accuracy: 0.5888\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2544 - accuracy: 0.5908 - val_loss: 2.3061 - val_accuracy: 0.5879\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2567 - accuracy: 0.5904 - val_loss: 2.3080 - val_accuracy: 0.5880\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 2.2435 - accuracy: 0.5908 - val_loss: 2.2993 - val_accuracy: 0.5883\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 2.2377 - accuracy: 0.5913 - val_loss: 2.3046 - val_accuracy: 0.5873\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 2.2361 - accuracy: 0.5918 - val_loss: 2.2964 - val_accuracy: 0.5885\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 1s 40ms/step - loss: 2.2330 - accuracy: 0.5919 - val_loss: 2.3037 - val_accuracy: 0.5882\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 2.2306 - accuracy: 0.5914 - val_loss: 2.2981 - val_accuracy: 0.5873\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 2.2286 - accuracy: 0.5917 - val_loss: 2.2956 - val_accuracy: 0.5883\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 2.2259 - accuracy: 0.5925 - val_loss: 2.2975 - val_accuracy: 0.5886\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2176 - accuracy: 0.5924 - val_loss: 2.2890 - val_accuracy: 0.5881\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.2160 - accuracy: 0.5926 - val_loss: 2.2935 - val_accuracy: 0.5883\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2114 - accuracy: 0.5928 - val_loss: 2.2876 - val_accuracy: 0.5881\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2063 - accuracy: 0.5932 - val_loss: 2.2880 - val_accuracy: 0.5875\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 2.2058 - accuracy: 0.5934 - val_loss: 2.2975 - val_accuracy: 0.5867\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2019 - accuracy: 0.5934 - val_loss: 2.2877 - val_accuracy: 0.5878\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.2026 - accuracy: 0.5935 - val_loss: 2.2891 - val_accuracy: 0.5880\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1954 - accuracy: 0.5940 - val_loss: 2.2879 - val_accuracy: 0.5867\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1948 - accuracy: 0.5936 - val_loss: 2.2901 - val_accuracy: 0.5870\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1888 - accuracy: 0.5943 - val_loss: 2.2878 - val_accuracy: 0.5874\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1879 - accuracy: 0.5943 - val_loss: 2.2894 - val_accuracy: 0.5856\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.1879 - accuracy: 0.5948 - val_loss: 2.2867 - val_accuracy: 0.5861\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1839 - accuracy: 0.5944 - val_loss: 2.2939 - val_accuracy: 0.5856\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.1827 - accuracy: 0.5946 - val_loss: 2.2857 - val_accuracy: 0.5873\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 2.1754 - accuracy: 0.5947 - val_loss: 2.2889 - val_accuracy: 0.5864\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 2.1754 - accuracy: 0.5953 - val_loss: 2.2926 - val_accuracy: 0.5870\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 2.1849 - accuracy: 0.5939 - val_loss: 2.2891 - val_accuracy: 0.5870\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 2.1715 - accuracy: 0.5951 - val_loss: 2.3004 - val_accuracy: 0.5851\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 2.1799 - accuracy: 0.5938 - val_loss: 2.2858 - val_accuracy: 0.5867\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1653 - accuracy: 0.5962 - val_loss: 2.2882 - val_accuracy: 0.5867\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1797 - accuracy: 0.5943 - val_loss: 2.2967 - val_accuracy: 0.5856\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1612 - accuracy: 0.5958 - val_loss: 2.2934 - val_accuracy: 0.5859\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1599 - accuracy: 0.5961 - val_loss: 2.2887 - val_accuracy: 0.5856\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1502 - accuracy: 0.5964 - val_loss: 2.2901 - val_accuracy: 0.5856\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1533 - accuracy: 0.5961 - val_loss: 2.2895 - val_accuracy: 0.5856\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1498 - accuracy: 0.5967 - val_loss: 2.2911 - val_accuracy: 0.5858\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 2.1452 - accuracy: 0.5966 - val_loss: 2.2970 - val_accuracy: 0.5850\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1483 - accuracy: 0.5962 - val_loss: 2.2968 - val_accuracy: 0.5849\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1422 - accuracy: 0.5965 - val_loss: 2.2929 - val_accuracy: 0.5853\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1425 - accuracy: 0.5967 - val_loss: 2.3102 - val_accuracy: 0.5839\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1387 - accuracy: 0.5966 - val_loss: 2.2975 - val_accuracy: 0.5852\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1361 - accuracy: 0.5973 - val_loss: 2.2945 - val_accuracy: 0.5850\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 2.1363 - accuracy: 0.5971 - val_loss: 2.2961 - val_accuracy: 0.5855\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 2.1313 - accuracy: 0.5974 - val_loss: 2.2966 - val_accuracy: 0.5845\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1270 - accuracy: 0.5972 - val_loss: 2.3003 - val_accuracy: 0.5849\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1237 - accuracy: 0.5971 - val_loss: 2.2973 - val_accuracy: 0.5856\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 2.1214 - accuracy: 0.5976 - val_loss: 2.3013 - val_accuracy: 0.5845\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 2.1215 - accuracy: 0.5971 - val_loss: 2.2958 - val_accuracy: 0.5837\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 2.1153 - accuracy: 0.5977 - val_loss: 2.2968 - val_accuracy: 0.5844\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 1s 32ms/step - loss: 2.1120 - accuracy: 0.5979 - val_loss: 2.2984 - val_accuracy: 0.5842\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 2.1126 - accuracy: 0.5982 - val_loss: 2.3035 - val_accuracy: 0.5840\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1114 - accuracy: 0.5982 - val_loss: 2.3004 - val_accuracy: 0.5838\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1121 - accuracy: 0.5983 - val_loss: 2.2998 - val_accuracy: 0.5846\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1072 - accuracy: 0.5972 - val_loss: 2.3062 - val_accuracy: 0.5837\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 2.1161 - accuracy: 0.5976 - val_loss: 2.3039 - val_accuracy: 0.5834\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1030 - accuracy: 0.5980 - val_loss: 2.3055 - val_accuracy: 0.5837\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 2.1005 - accuracy: 0.5979 - val_loss: 2.3044 - val_accuracy: 0.5828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7ecc2a5c90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the model\n",
        "embedding_dim = 50  # Adjust as needed\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_songs, output_dim=embedding_dim, input_length=None))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal, return_sequences=True))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_songs, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dfdead0d",
      "metadata": {
        "id": "dfdead0d"
      },
      "outputs": [],
      "source": [
        "# generate predictions until num predictions or Set 1\n",
        "def generate_predictions(model, seed_sequence, stop_song_index, num_predictions=10):\n",
        "    predicted_sequence = seed_sequence.copy()\n",
        "    predicted_set = set(predicted_sequence)\n",
        "\n",
        "    while len(predicted_sequence) < num_predictions:\n",
        "        next_song_probs = model.predict(np.array([predicted_sequence]))[0][-1]\n",
        "        # Exclude songs that have already been predicted\n",
        "        valid_probs = [prob if i not in predicted_set else 0 for i, prob in enumerate(next_song_probs)]\n",
        "        next_song_index = np.argmax(valid_probs)\n",
        "\n",
        "        if next_song_index == stop_song_index:\n",
        "            print(\"Got Set 1. \")\n",
        "            break\n",
        "\n",
        "        predicted_sequence.append(next_song_index)\n",
        "        predicted_set.add(next_song_index)\n",
        "\n",
        "    return predicted_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "121fd867",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "121fd867",
        "outputId": "99bf11db-ac96-42fb-b3cc-802be0d8754a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "org_list\n",
            "['set 1', 'you enjoy myself', 'lushington', 'possum', 'slave to the traffic light', 'sneakin sally through the alley', 'clod', 'peaches en regalia', 'the man who stepped into yesterday', 'avenu malkenu', 'the man who stepped into yesterday', 'makisupa policeman', 'ya mar', 'set 2', 'divided sky', 'funky bitch', 'harpua', 'bundle of joy', 'harpua', 'fluffhead', 'good times bad times', 'set e', 'golgi apparatus', 'corinna', 'letter to jimmy page']\n",
            "\n",
            "Seed Sequence:\n",
            "['set 1', 'you enjoy myself']\n",
            "\n",
            "Predicted Sequence:\n",
            "['family picture', 'alumni blues', 'golgi apparatus', 'wilson', 'possum', 'letter to jimmy page', 'chalk dust torture', 'harpua', 'divided sky', 'runaway jim', 'suzy greenberg', 'foam', 'llama', 'the landlady', 'reba', 'buried alive', 'guelah papyrus', 'poor heart', 'the man who stepped into yesterday', 'bouncing around the room', 'acdc bag']\n"
          ]
        }
      ],
      "source": [
        "# test example\n",
        "seed_index = 5  # test example\n",
        "#seed length\n",
        "seed_length = 2\n",
        "seed_sequence = songstring['full'].iloc[seed_index].split('|')\n",
        "\n",
        "# Tokenize the seed sequence\n",
        "seed_sequence = [song.replace('-', ' ') for song in seed_sequence][:seed_length]\n",
        "org_list =  [song.replace('-', ' ') for song in songstring['full'].iloc[seed_index].split('|')]\n",
        "seed_sequence_indices = [song_to_index[song] for song in seed_sequence]\n",
        "\n",
        "# pad/trunc seed to the required length\n",
        "seed_sequence_padded = pad_sequences([seed_sequence_indices], padding='pre', truncating='pre')[0]\n",
        "\n",
        "\n",
        "# stop if set 1 is encountered again\n",
        "stop_song = 'set 1'\n",
        "stop_song_index = song_to_index[stop_song]\n",
        "# set number of predictions to the original playlist - seed length, i.e. remaining songs pending from that playlist.\n",
        "num_predictions = len(org_list)- seed_length #10\n",
        "\n",
        "predicted_sequence = generate_predictions(model, seed_sequence_padded.tolist(), stop_song_index, num_predictions)\n",
        "\n",
        "# numerical predictions back to song names\n",
        "predicted_songs = [index_to_song[i] for i in predicted_sequence]\n",
        "\n",
        "# Print the seed sequence and predicted sequence\n",
        "print('\\norg_list')\n",
        "print(org_list)\n",
        "print(\"\\nSeed Sequence:\")\n",
        "print(seed_sequence)\n",
        "print(\"\\nPredicted Sequence:\")\n",
        "print(predicted_songs[seed_length:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8ced0820",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ced0820",
        "outputId": "2d1153ae-918f-430a-ce7d-77e0342b9b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Songs in Predicted Sequence:\n",
            "['the man who stepped into yesterday', 'divided sky', 'harpua', 'golgi apparatus', 'possum', 'letter to jimmy page']\n",
            "Number of Matching Songs: 6\n",
            "Percentage of Matching Songs: 31.57894736842105\n"
          ]
        }
      ],
      "source": [
        "# Assuming org_list, seed_sequence, stopword_list, and predicted_sequence are lists of songs\n",
        "\n",
        "stopword_list = {'set 1', 'set 2', 'set 3', 'set 4', 'set 5', 'set 6', 'set e'}\n",
        "\n",
        "\n",
        "# Convert the lists to sets\n",
        "org_set = set(org_list)\n",
        "seed_set = set(seed_sequence)\n",
        "\n",
        "# Find the songs in org_list but not in seed_sequence\n",
        "not_in_seed_sequence = org_set - seed_set\n",
        "\n",
        "# Remove songs in stopword_list\n",
        "filtered_songs = [song.strip() for song in not_in_seed_sequence if song not in stopword_list]\n",
        "\n",
        "# Remove songs in stopword_list from predicted_sequence\n",
        "predicted_sequence = [song.strip() for song in predicted_songs[seed_length:] if song not in stopword_list]\n",
        "\n",
        "# Count the number of matching songs\n",
        "matching_songs = [song for song in filtered_songs if song in predicted_sequence]\n",
        "num_matching_songs = len(matching_songs)\n",
        "\n",
        "# Calculate the percentage of matching songs\n",
        "percentage_matching = (num_matching_songs / len(filtered_songs)) * 100\n",
        "\n",
        "print(\"Matching Songs in Predicted Sequence:\")\n",
        "print(matching_songs)\n",
        "print(\"Number of Matching Songs:\", num_matching_songs)\n",
        "print(\"Percentage of Matching Songs:\", percentage_matching)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0a4b92",
      "metadata": {
        "id": "de0a4b92"
      },
      "outputs": [],
      "source": [
        "## Splitting by date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "66d8f49e",
      "metadata": {
        "id": "66d8f49e"
      },
      "outputs": [],
      "source": [
        "split_date = '2010-12-31'\n",
        "\n",
        "# Split the data\n",
        "train_data = songstring[songstring['showdate'] < split_date]\n",
        "test_data = songstring[songstring['showdate'] >= split_date]\n",
        "\n",
        "# Tokenize songs in the training and testing data\n",
        "train_songs = train_data['full'].str.split('|').apply(lambda x: [song.replace('-', ' ') for song in x])\n",
        "test_songs = test_data['full'].str.split('|').apply(lambda x: [song.replace('-', ' ') for song in x])\n",
        "\n",
        "# Create unique songs and encode into numerical values\n",
        "all_songs = list(set(song for sublist in train_songs for song in sublist))\n",
        "num_songs = len(all_songs)\n",
        "\n",
        "song_to_index = {song: i for i, song in enumerate(all_songs)}\n",
        "index_to_song = {i: song for i, song in enumerate(all_songs)}\n",
        "\n",
        "# Encode sequences for training data\n",
        "train_input_sequences = []\n",
        "train_target_sequences = []\n",
        "\n",
        "for i in range(len(train_songs) - 1):\n",
        "    input_seq = train_songs.iloc[i]\n",
        "    target_seq = train_songs.iloc[i + 1]\n",
        "    train_input_sequences.append([song_to_index[song] for song in input_seq])\n",
        "    train_target_sequences.append([song_to_index[song] for song in target_seq])\n",
        "\n",
        "# Pad sequences for training and testing data\n",
        "X_train = pad_sequences(train_input_sequences, padding='pre', truncating='pre')\n",
        "y_train = pad_sequences(train_target_sequences, padding='pre', truncating='pre')\n",
        "# Encode sequences for testing data\n",
        "test_input_sequences = []\n",
        "test_target_sequences = []\n",
        "\n",
        "for i in range(len(test_songs) - 1):\n",
        "    input_seq = test_songs.iloc[i]\n",
        "    target_seq = test_songs.iloc[i + 1]\n",
        "\n",
        "    # Handle missing songs in the dictionary\n",
        "    input_sequence_indices = [song_to_index.get(song, -1) for song in input_seq]\n",
        "    target_sequence_indices = [song_to_index.get(song, -1) for song in target_seq]\n",
        "\n",
        "    # Filter out songs with index -1 (not found in the dictionary)\n",
        "    input_sequence_indices = [index for index in input_sequence_indices if index != -1]\n",
        "    target_sequence_indices = [index for index in target_sequence_indices if index != -1]\n",
        "\n",
        "    test_input_sequences.append(input_sequence_indices)\n",
        "    test_target_sequences.append(target_sequence_indices)\n",
        "\n",
        "# Pad sequences for testing data\n",
        "X_test = pad_sequences(test_input_sequences, padding='pre', truncating='pre')\n",
        "y_test = pad_sequences(test_target_sequences, padding='pre', truncating='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "41139f88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41139f88",
        "outputId": "8240f3b2-099d-4467-8739-bdd7e167d22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 16s 202ms/step - loss: 4.7789 - accuracy: 0.5087 - val_loss: 3.4108 - val_accuracy: 0.5672\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 3.2688 - accuracy: 0.5450 - val_loss: 3.1939 - val_accuracy: 0.5672\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 3.0967 - accuracy: 0.5450 - val_loss: 3.0293 - val_accuracy: 0.5672\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 2s 48ms/step - loss: 2.9209 - accuracy: 0.5450 - val_loss: 2.8345 - val_accuracy: 0.5672\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 1s 32ms/step - loss: 2.7518 - accuracy: 0.5450 - val_loss: 2.7066 - val_accuracy: 0.5663\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.6323 - accuracy: 0.5456 - val_loss: 2.6372 - val_accuracy: 0.5663\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.5709 - accuracy: 0.5491 - val_loss: 2.5851 - val_accuracy: 0.5663\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 2.5286 - accuracy: 0.5533 - val_loss: 2.5848 - val_accuracy: 0.5846\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.5077 - accuracy: 0.5556 - val_loss: 2.5251 - val_accuracy: 0.5878\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 2s 49ms/step - loss: 2.4871 - accuracy: 0.5590 - val_loss: 2.5248 - val_accuracy: 0.5892\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 2s 61ms/step - loss: 2.4647 - accuracy: 0.5624 - val_loss: 2.4935 - val_accuracy: 0.5997\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 2.4586 - accuracy: 0.5654 - val_loss: 2.6037 - val_accuracy: 0.5735\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 2.4451 - accuracy: 0.5677 - val_loss: 2.5091 - val_accuracy: 0.5927\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 2.4320 - accuracy: 0.5685 - val_loss: 2.5053 - val_accuracy: 0.5867\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.4239 - accuracy: 0.5724 - val_loss: 2.4734 - val_accuracy: 0.5952\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.4116 - accuracy: 0.5739 - val_loss: 2.5096 - val_accuracy: 0.5923\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.4075 - accuracy: 0.5746 - val_loss: 2.5231 - val_accuracy: 0.5805\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.4044 - accuracy: 0.5740 - val_loss: 2.4745 - val_accuracy: 0.5940\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.3944 - accuracy: 0.5766 - val_loss: 2.5284 - val_accuracy: 0.5832\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 1s 30ms/step - loss: 2.3867 - accuracy: 0.5781 - val_loss: 2.4992 - val_accuracy: 0.5893\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 2.3766 - accuracy: 0.5781 - val_loss: 2.5009 - val_accuracy: 0.5863\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 2.3717 - accuracy: 0.5788 - val_loss: 2.4978 - val_accuracy: 0.5862\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3700 - accuracy: 0.5791 - val_loss: 2.5393 - val_accuracy: 0.5829\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 2.3670 - accuracy: 0.5786 - val_loss: 2.4640 - val_accuracy: 0.5937\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 2.3674 - accuracy: 0.5784 - val_loss: 2.5310 - val_accuracy: 0.5859\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 1s 28ms/step - loss: 2.3540 - accuracy: 0.5791 - val_loss: 2.4981 - val_accuracy: 0.5888\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 1s 30ms/step - loss: 2.3482 - accuracy: 0.5798 - val_loss: 2.5222 - val_accuracy: 0.5845\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 1s 25ms/step - loss: 2.3460 - accuracy: 0.5797 - val_loss: 2.5350 - val_accuracy: 0.5835\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3419 - accuracy: 0.5799 - val_loss: 2.5652 - val_accuracy: 0.5820\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 2.3361 - accuracy: 0.5806 - val_loss: 2.6313 - val_accuracy: 0.5791\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 2.3332 - accuracy: 0.5808 - val_loss: 2.6294 - val_accuracy: 0.5788\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.3333 - accuracy: 0.5809 - val_loss: 2.6619 - val_accuracy: 0.5794\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.3265 - accuracy: 0.5810 - val_loss: 2.4660 - val_accuracy: 0.5973\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 2.3187 - accuracy: 0.5822 - val_loss: 2.5859 - val_accuracy: 0.5822\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3103 - accuracy: 0.5826 - val_loss: 2.5797 - val_accuracy: 0.5843\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3078 - accuracy: 0.5824 - val_loss: 2.6039 - val_accuracy: 0.5811\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3059 - accuracy: 0.5821 - val_loss: 2.6080 - val_accuracy: 0.5813\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2997 - accuracy: 0.5827 - val_loss: 2.5845 - val_accuracy: 0.5807\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3010 - accuracy: 0.5820 - val_loss: 2.6002 - val_accuracy: 0.5800\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2903 - accuracy: 0.5836 - val_loss: 2.5505 - val_accuracy: 0.5882\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.2827 - accuracy: 0.5833 - val_loss: 2.5288 - val_accuracy: 0.5892\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2836 - accuracy: 0.5832 - val_loss: 2.5731 - val_accuracy: 0.5871\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2864 - accuracy: 0.5822 - val_loss: 2.4333 - val_accuracy: 0.5974\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 2.2747 - accuracy: 0.5833 - val_loss: 2.5003 - val_accuracy: 0.5935\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 2.2606 - accuracy: 0.5845 - val_loss: 2.5509 - val_accuracy: 0.5886\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 1s 30ms/step - loss: 2.2622 - accuracy: 0.5841 - val_loss: 2.5161 - val_accuracy: 0.5920\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 1s 26ms/step - loss: 2.2542 - accuracy: 0.5841 - val_loss: 2.5638 - val_accuracy: 0.5844\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2475 - accuracy: 0.5844 - val_loss: 2.5218 - val_accuracy: 0.5894\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2472 - accuracy: 0.5843 - val_loss: 2.4570 - val_accuracy: 0.5946\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 2.2459 - accuracy: 0.5841 - val_loss: 2.5007 - val_accuracy: 0.5916\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2388 - accuracy: 0.5850 - val_loss: 2.5500 - val_accuracy: 0.5896\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 2.2325 - accuracy: 0.5846 - val_loss: 2.5010 - val_accuracy: 0.5911\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2361 - accuracy: 0.5847 - val_loss: 2.5465 - val_accuracy: 0.5878\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2332 - accuracy: 0.5843 - val_loss: 2.5051 - val_accuracy: 0.5927\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2393 - accuracy: 0.5835 - val_loss: 2.7207 - val_accuracy: 0.5763\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2335 - accuracy: 0.5840 - val_loss: 2.5815 - val_accuracy: 0.5867\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2204 - accuracy: 0.5851 - val_loss: 2.5681 - val_accuracy: 0.5873\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2153 - accuracy: 0.5857 - val_loss: 2.4819 - val_accuracy: 0.5946\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2156 - accuracy: 0.5855 - val_loss: 2.6132 - val_accuracy: 0.5847\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2181 - accuracy: 0.5850 - val_loss: 2.4907 - val_accuracy: 0.5908\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.2092 - accuracy: 0.5861 - val_loss: 2.5832 - val_accuracy: 0.5855\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2083 - accuracy: 0.5861 - val_loss: 2.5722 - val_accuracy: 0.5865\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 1s 27ms/step - loss: 2.2081 - accuracy: 0.5863 - val_loss: 2.4999 - val_accuracy: 0.5925\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 2.2030 - accuracy: 0.5864 - val_loss: 2.5235 - val_accuracy: 0.5895\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 1s 30ms/step - loss: 2.2016 - accuracy: 0.5867 - val_loss: 2.5561 - val_accuracy: 0.5871\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 1s 34ms/step - loss: 2.1953 - accuracy: 0.5872 - val_loss: 2.6067 - val_accuracy: 0.5839\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1973 - accuracy: 0.5868 - val_loss: 2.5082 - val_accuracy: 0.5897\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2000 - accuracy: 0.5867 - val_loss: 2.4921 - val_accuracy: 0.5900\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1943 - accuracy: 0.5865 - val_loss: 2.5370 - val_accuracy: 0.5882\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1880 - accuracy: 0.5870 - val_loss: 2.5414 - val_accuracy: 0.5856\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1892 - accuracy: 0.5876 - val_loss: 2.5297 - val_accuracy: 0.5859\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1865 - accuracy: 0.5869 - val_loss: 2.5950 - val_accuracy: 0.5826\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1809 - accuracy: 0.5877 - val_loss: 2.5993 - val_accuracy: 0.5845\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1787 - accuracy: 0.5878 - val_loss: 2.5977 - val_accuracy: 0.5822\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1803 - accuracy: 0.5879 - val_loss: 2.6558 - val_accuracy: 0.5778\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1783 - accuracy: 0.5878 - val_loss: 2.6625 - val_accuracy: 0.5790\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1708 - accuracy: 0.5886 - val_loss: 2.6099 - val_accuracy: 0.5820\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1804 - accuracy: 0.5871 - val_loss: 2.6092 - val_accuracy: 0.5812\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1702 - accuracy: 0.5883 - val_loss: 2.6846 - val_accuracy: 0.5800\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1617 - accuracy: 0.5887 - val_loss: 2.6371 - val_accuracy: 0.5789\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1615 - accuracy: 0.5886 - val_loss: 2.6226 - val_accuracy: 0.5789\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1618 - accuracy: 0.5883 - val_loss: 2.5762 - val_accuracy: 0.5813\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 2.1533 - accuracy: 0.5895 - val_loss: 2.6722 - val_accuracy: 0.5766\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 1s 32ms/step - loss: 2.1506 - accuracy: 0.5891 - val_loss: 2.5475 - val_accuracy: 0.5833\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.1534 - accuracy: 0.5889 - val_loss: 2.5907 - val_accuracy: 0.5798\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.1466 - accuracy: 0.5893 - val_loss: 2.5961 - val_accuracy: 0.5810\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1429 - accuracy: 0.5894 - val_loss: 2.5932 - val_accuracy: 0.5807\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1460 - accuracy: 0.5891 - val_loss: 2.5063 - val_accuracy: 0.5863\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1461 - accuracy: 0.5892 - val_loss: 2.5765 - val_accuracy: 0.5815\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1356 - accuracy: 0.5897 - val_loss: 2.6354 - val_accuracy: 0.5794\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1301 - accuracy: 0.5899 - val_loss: 2.6383 - val_accuracy: 0.5786\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1273 - accuracy: 0.5896 - val_loss: 2.5587 - val_accuracy: 0.5808\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1454 - accuracy: 0.5882 - val_loss: 2.6734 - val_accuracy: 0.5805\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1438 - accuracy: 0.5884 - val_loss: 2.5947 - val_accuracy: 0.5841\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 2.1225 - accuracy: 0.5909 - val_loss: 2.6005 - val_accuracy: 0.5788\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1182 - accuracy: 0.5907 - val_loss: 2.6901 - val_accuracy: 0.5747\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1142 - accuracy: 0.5911 - val_loss: 2.6654 - val_accuracy: 0.5776\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.1087 - accuracy: 0.5914 - val_loss: 2.6253 - val_accuracy: 0.5780\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 2.1109 - accuracy: 0.5910 - val_loss: 2.6565 - val_accuracy: 0.5759\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.1117 - accuracy: 0.5907 - val_loss: 2.7051 - val_accuracy: 0.5771\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7efc338d00>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "\n",
        "\n",
        "# model\n",
        "embedding_dim = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_songs, output_dim=embedding_dim, input_length=None))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal, return_sequences=True))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_songs, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "68270f59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68270f59",
        "outputId": "73e51b61-57ad-477e-f0d4-400a9ff3313f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "org_list\n",
            "['set 1', 'the landlady', 'runaway jim', 'divided sky', '46 days', 'stealing time from the faulty plan', 'sugar shack', 'shade', 'halfway to the moon', 'everythings right', 'set 2', 'energy', 'gotta jibboo', 'soul planet', 'rift', 'reba', 'martian monster', 'broken heart attack', 'hold your head up', 'martian monster', 'possum', 'slave to the traffic light', 'set e', 'waste', 'first tube']\n",
            "\n",
            "Seed Sequence:\n",
            "['set 1', 'the landlady']\n",
            "\n",
            "Predicted Sequence:\n",
            "['night nurse', 'feel the heat', 'the other one', 'wild child', 'let it loose', 'family picture', 'blackberry blossom', 'golgi apparatus', 'alumni blues', 'divided sky', 'letter to jimmy page', 'the man who stepped into yesterday', 'possum', 'buried alive', 'suzy greenberg', 'chalk dust torture', 'wilson', 'reba', 'runaway jim', 'foam', 'llama']\n"
          ]
        }
      ],
      "source": [
        "# test example\n",
        "seed_index = 1500 # test example\n",
        "#seed length\n",
        "seed_length =2\n",
        "seed_sequence = songstring['full'].iloc[seed_index].split('|')\n",
        "\n",
        "# Tokenize the seed sequence\n",
        "seed_sequence = [song.replace('-', ' ') for song in seed_sequence][:seed_length]\n",
        "org_list =  [song.replace('-', ' ') for song in songstring['full'].iloc[seed_index].split('|')]\n",
        "seed_sequence_indices = [song_to_index[song] for song in seed_sequence]\n",
        "\n",
        "# pad/trunc seed to the required length\n",
        "seed_sequence_padded = pad_sequences([seed_sequence_indices], padding='pre', truncating='pre')[0]\n",
        "\n",
        "\n",
        "# stop if set 1 is encountered again\n",
        "stop_song = 'set 1'\n",
        "stop_song_index = song_to_index[stop_song]\n",
        "# set number of predictions to the original playlist - seed length, i.e. remaining songs pending from that playlist.\n",
        "num_predictions = len(org_list)- seed_length #10\n",
        "\n",
        "predicted_sequence = generate_predictions(model, seed_sequence_padded.tolist(), stop_song_index, num_predictions)\n",
        "\n",
        "# numerical predictions back to song names\n",
        "predicted_songs = [index_to_song[i] for i in predicted_sequence]\n",
        "\n",
        "# Print the seed sequence and predicted sequence\n",
        "print('\\norg_list')\n",
        "print(org_list)\n",
        "print(\"\\nSeed Sequence:\")\n",
        "print(seed_sequence)\n",
        "print(\"\\nPredicted Sequence:\")\n",
        "print(predicted_songs[seed_length:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "087da45e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "087da45e",
        "outputId": "57dfeab3-4a74-433a-98a4-4bf82a4abd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Songs in Predicted Sequence:\n",
            "['runaway jim', 'divided sky', 'possum', 'reba']\n",
            "Number of Matching Songs: 4\n",
            "Percentage of Matching Songs: 20.0\n"
          ]
        }
      ],
      "source": [
        "# Assuming org_list, seed_sequence, stopword_list, and predicted_sequence are lists of songs\n",
        "\n",
        "stopword_list = {'set 1', 'set 2', 'set 3', 'set 4', 'set 5', 'set 6', 'set e'}\n",
        "\n",
        "\n",
        "# Convert the lists to sets\n",
        "org_set = set(org_list)\n",
        "seed_set = set(seed_sequence)\n",
        "\n",
        "# Find the songs in org_list but not in seed_sequence\n",
        "not_in_seed_sequence = org_set - seed_set\n",
        "\n",
        "# Remove songs in stopword_list\n",
        "filtered_songs = [song.strip() for song in not_in_seed_sequence if song not in stopword_list]\n",
        "\n",
        "# Remove songs in stopword_list from predicted_sequence\n",
        "predicted_sequence = [song.strip() for song in predicted_songs[seed_length:] if song not in stopword_list]\n",
        "\n",
        "# Count the number of matching songs\n",
        "matching_songs = [song for song in filtered_songs if song in predicted_sequence]\n",
        "num_matching_songs = len(matching_songs)\n",
        "\n",
        "# Calculate the percentage of matching songs\n",
        "percentage_matching = (num_matching_songs / len(filtered_songs)) * 100\n",
        "\n",
        "print(\"Matching Songs in Predicted Sequence:\")\n",
        "print(matching_songs)\n",
        "print(\"Number of Matching Songs:\", num_matching_songs)\n",
        "print(\"Percentage of Matching Songs:\", percentage_matching)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "songs = songstring['full'].str.split('|').apply(lambda x: [song.replace('-', ' ') for song in x])\n",
        "unique_songs = list(set(song for sublist in songs for song in sublist))\n",
        "num_songs = len(unique_songs)\n",
        "\n",
        "# Encode songs into numerical values\n",
        "song_to_index = {song: i for i, song in enumerate(unique_songs)}\n",
        "index_to_song = {i: song for i, song in enumerate(unique_songs)}"
      ],
      "metadata": {
        "id": "VgwIrEA1c5xT"
      },
      "id": "VgwIrEA1c5xT",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all = []\n",
        "y_train_all = []\n",
        "\n",
        "for song_list in songs:\n",
        "    sequences = []\n",
        "    for i in range(1, len(song_list)):\n",
        "        sequence = song_list[:i + 1]  # Take the first i+1 songs\n",
        "        sequences.append(sequence)\n",
        "\n",
        "    # Create input (X_train) and target (y_train) sequences for the current list\n",
        "    X_train = [seq[:-1] for seq in sequences]  # All songs except the last one\n",
        "    y_train = [seq[-1] for seq in sequences]  # The last song\n",
        "\n",
        "    # Convert song titles to corresponding indices using the mapping\n",
        "    X_train = [[song_to_index[song] for song in seq] for seq in X_train]\n",
        "    y_train = [song_to_index[song] for song in y_train]\n",
        "\n",
        "    # Append the sequences for the current list to the overall X_train_all and y_train_all\n",
        "    X_train_all.extend(X_train)\n",
        "    y_train_all.extend(y_train)"
      ],
      "metadata": {
        "id": "hYM2rfIOUD77"
      },
      "id": "hYM2rfIOUD77",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all[0],X_train_all[1],X_train_all[2],X_train_all[3],X_train_all[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlACNhwGUG5b",
        "outputId": "8c605a6d-ec72-436d-9b0a-dfe6339b91b8"
      },
      "id": "wlACNhwGUG5b",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([279],\n",
              " [279, 82],\n",
              " [279, 82, 179],\n",
              " [279, 82, 179, 342],\n",
              " [279, 82, 179, 342, 464])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pad sequences to make them of the same length\n",
        "X_train_all_padded = pad_sequences(X_train_all, padding='pre', value=0.0)  # Use a value that won't interfere with your song indices\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train_all_padded = np.array(X_train_all_padded)\n",
        "y_train_all = np.array(y_train_all)"
      ],
      "metadata": {
        "id": "VtzZ4bsGUKTr"
      },
      "id": "VtzZ4bsGUKTr",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_songs, output_dim=embedding_dim, input_length=None))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal, return_sequences=True))\n",
        "model.add(LSTM(units=100,activation='tanh', kernel_initializer=he_normal))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=num_songs, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "1qTtTL0_UOau"
      },
      "id": "1qTtTL0_UOau",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es=  EarlyStopping(monitor='val_loss',patience=10)\n",
        "model.fit(X_train_all_padded, y_train_all, epochs=100, batch_size=32, validation_split=0.3,callbacks = [es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl3uYZNkUQf4",
        "outputId": "1e9c6cb3-e6e0-454d-98f7-7c0b99c20036"
      },
      "id": "xl3uYZNkUQf4",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 33s 31ms/step - loss: 5.1820 - accuracy: 0.0678 - val_loss: 6.0132 - val_accuracy: 0.0897\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 14s 18ms/step - loss: 4.7474 - accuracy: 0.1001 - val_loss: 5.9906 - val_accuracy: 0.1018\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 14s 18ms/step - loss: 4.5138 - accuracy: 0.1238 - val_loss: 6.0566 - val_accuracy: 0.1181\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 15s 18ms/step - loss: 4.3661 - accuracy: 0.1447 - val_loss: 6.1624 - val_accuracy: 0.1146\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 14s 17ms/step - loss: 4.2482 - accuracy: 0.1574 - val_loss: 6.1405 - val_accuracy: 0.1205\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 14s 18ms/step - loss: 4.1536 - accuracy: 0.1679 - val_loss: 6.2686 - val_accuracy: 0.1227\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 13s 17ms/step - loss: 4.0603 - accuracy: 0.1776 - val_loss: 6.2354 - val_accuracy: 0.1241\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 14s 17ms/step - loss: 3.9888 - accuracy: 0.1815 - val_loss: 6.2846 - val_accuracy: 0.1246\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 14s 17ms/step - loss: 3.9338 - accuracy: 0.1892 - val_loss: 6.3455 - val_accuracy: 0.1251\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 15s 19ms/step - loss: 3.8787 - accuracy: 0.1940 - val_loss: 6.4560 - val_accuracy: 0.1263\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 15s 18ms/step - loss: 3.8331 - accuracy: 0.1976 - val_loss: 6.4752 - val_accuracy: 0.1249\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 13s 17ms/step - loss: 3.7912 - accuracy: 0.2016 - val_loss: 6.6322 - val_accuracy: 0.1245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7ea239dde0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezTQ21siU5fK"
      },
      "id": "ezTQ21siU5fK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
